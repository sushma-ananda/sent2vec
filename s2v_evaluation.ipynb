{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sent2vec\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sentence embedding model\n",
    "model_path = '/Users/sakoju/Documents/10715/Fall2018/Project/sent2vec/pre-trained-models/'\n",
    "model_wi_1 = sent2vec.Sent2vecModel()\n",
    "model_wi_1.load_model(model_path + 'wiki_bigrams.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_embedding(sents, model):\n",
    "    \"\"\"\n",
    "    sents: array, n sentences,\n",
    "    model: embedding model\n",
    "    \"\"\"\n",
    "    tknzr = TweetTokenizer()\n",
    "    n = len(sents)\n",
    "    tokenized_sents = []\n",
    "    for i in range (n):\n",
    "        tokenized_sents.append(' '.join(tknzr.tokenize(sents[i])).lower())\n",
    "    emb = model.embed_sentences(tokenized_sents)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movie reviews and preprocessing\n",
    "mr_file_neg = open('/Users/sakoju/Documents/10715/Fall2018/Project/sent2vec/datasets/rt-polarity.neg', encoding=\"latin-1\")\n",
    "mr_sent_neg = mr_file_neg.readlines()\n",
    "mr_file_neg.close()\n",
    "mr_file_pos = open('/Users/sakoju/Documents/10715/Fall2018/Project/sent2vec/datasets/rt-polarity.pos', encoding=\"latin-1\")\n",
    "mr_sent_pos = mr_file_pos.readlines()\n",
    "mr_file_pos.close()\n",
    "mr_sent_neg = np.array(mr_sent_neg)\n",
    "mr_sent_pos = np.array(mr_sent_pos)\n",
    "mr_y_neg = np.zeros_like(mr_sent_neg)\n",
    "for i in range(len(mr_y_neg)):\n",
    "    mr_y_neg[i] = 0\n",
    "mr_y_pos = np.ones_like(mr_sent_pos)\n",
    "mr_sent = np.concatenate((mr_sent_pos, mr_sent_neg))\n",
    "mr_y = np.concatenate((mr_y_pos, mr_y_neg))\n",
    "\n",
    "random.seed(2)\n",
    "random.shuffle(mr_sent)\n",
    "random.seed(2)\n",
    "random.shuffle(mr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding movie review\n",
    "mr_x = block_embedding(mr_sent, model_wi_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression to classify the movie review\n",
    "def nestedCV(X, Y, Cs, innercv, outercv):\n",
    "    \"\"\"\n",
    "    Nested Cross Validation to select the best hyperparameters\n",
    "    and evaluate the logistic regression model.\n",
    "    :param X: n by d array, input features\n",
    "    :param Y: n by 1 array, labels\n",
    "    :param Cs: List or Array of candidates parameters for penalty in LR\n",
    "    :param innercv: int, fold of the inner cross validation\n",
    "    :param outercv: int, fold of the outer cross validation\n",
    "    :return: average score of cross validation\n",
    "    \"\"\"\n",
    "    clf_inner = GridSearchCV(estimator=LogisticRegression(), param_grid=Cs, cv=innercv)\n",
    "    clf_inner.fit(X, Y)\n",
    "    C_best = clf_inner.best_params_['C']\n",
    "    clf_outer = LogisticRegression(C=C_best)\n",
    "    scores = cross_val_score(clf_outer, X, Y, cv=outercv)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sakoju/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7597073719752392\n"
     ]
    }
   ],
   "source": [
    "# classify the movie reviews and see the accuracy\n",
    "sc = StandardScaler()\n",
    "mr_x_std = sc.fit_transform(mr_x)\n",
    "\n",
    "# create penalty coefficients candidates in logistic regression\n",
    "C_candidates = dict(C=np.arange(5, 10, 1))\n",
    "\n",
    "# nested CV for logistic regression\n",
    "score = nestedCV(mr_x_std, mr_y, C_candidates, 3, 3)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate STS using cosine similarity\n",
    "# and compare the results with the gold standard.\n",
    "# sentsets: sentence datasets:\n",
    "#           deft-forum, deft-news, headlines, images, OnWM, tweet-news\n",
    "def STS_eval(sentset, model):\n",
    "    \"\"\"\n",
    "    Evaluate the similarities of \n",
    "    :param sentset: string, sentence dataset\n",
    "    :param model: sentence embedding model\n",
    "    :return: cosine similarity, of all pairs of sentences\n",
    "             pearson & spearman coefficients compared to gold standard\n",
    "    \"\"\"\n",
    "    sent_file = open('sts-en-test-gs-2014/STS.input.'+sentset+'.txt')\n",
    "    sent_data = sent_file.readlines()\n",
    "    sent_file.close()\n",
    "    gs_file = open('sts-en-test-gs-2014/STS.gs.'+sentset+'.txt')\n",
    "    gs_data = np.array(gs_file.readlines(), dtype=float)\n",
    "    gs_file.close()\n",
    "    splited_sent = []\n",
    "    n = len(sent_data)\n",
    "    for i in range(n):\n",
    "        splited_sent.append(re.split(r'\\t+', sent_data[i]))\n",
    "    splited_sent = np.array(splited_sent)\n",
    "    sent_1 = splited_sent[:,0]\n",
    "    sent_2 = splited_sent[:,1]\n",
    "    x_1 = block_embedding(sent_1, model)\n",
    "    x_2 = block_embedding(sent_2, model)\n",
    "    cosine = []\n",
    "\n",
    "    for i in range(n):\n",
    "        v1 = x_1[i]\n",
    "        v2 = x_2[i]\n",
    "        cos_i = cos([v1], [v2])\n",
    "        cosine.append(cos_i[0][0])\n",
    "    \n",
    "    print(np.shape(cosine))\n",
    "    print(np.shape(gs_data))\n",
    "    pearson = pearsonr(cosine, gs_data)\n",
    "    spearman = spearmanr(cosine, gs_data)\n",
    "    \n",
    "    return cosine, gs_data, pearson, spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n",
      "spearman correlation with gs: 0.648515617391334\n",
      "pearson correlation with gs: 0.704973999525268\n"
     ]
    }
   ],
   "source": [
    "cos_news, gs_news, pearson_news, spearman_news = STS_eval('deft-news', model_wi_1)\n",
    "\n",
    "print('spearman correlation with gs:',  spearman_news[0])\n",
    "print('pearson correlation with gs:', pearson_news[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
